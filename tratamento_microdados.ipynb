{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08fa8433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\gabriel.pessoli_v4co\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\gabriel.pessoli_v4co\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabriel.pessoli_v4co\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabriel.pessoli_v4co\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabriel.pessoli_v4co\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabriel.pessoli_v4co\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\gabriel.pessoli_v4co\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (22.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyarrow\n",
    "\n",
    "import pandas as pd \n",
    "import gc ##módulo para limpeza\n",
    "import os\n",
    "lista_arquivos = [\n",
    "    './Dados/Microdados/MICRODADOS_ENEM_2018.csv',\n",
    "    './Dados/Microdados/MICRODADOS_ENEM_2019.csv',\n",
    "    './Dados/Microdados/MICRODADOS_ENEM_2020.csv',\n",
    "    './Dados/Microdados/MICRODADOS_ENEM_2021.csv',\n",
    "    './Dados/Microdados/MICRODADOS_ENEM_2022.csv',\n",
    "    './Dados/Microdados/MICRODADOS_ENEM_2023.csv'\n",
    "    ]\n",
    "\n",
    "lista_de_amostras = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6bed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processando o arquivo: ./Dados/Microdados/MICRODADOS_ENEM_2018.csv\n",
      "Ano: 2018\n",
      "Arquivo de 2018 processado\n",
      "processando o arquivo: ./Dados/Microdados/MICRODADOS_ENEM_2019.csv\n",
      "Ano: 2019\n",
      "Arquivo de 2019 processado\n",
      "processando o arquivo: ./Dados/Microdados/MICRODADOS_ENEM_2020.csv\n",
      "Ano: 2020\n",
      "Arquivo de 2020 processado\n",
      "processando o arquivo: ./Dados/Microdados/MICRODADOS_ENEM_2021.csv\n",
      "Ano: 2021\n",
      "Arquivo de 2021 processado\n",
      "processando o arquivo: ./Dados/Microdados/MICRODADOS_ENEM_2022.csv\n",
      "Ano: 2022\n",
      "Arquivo de 2022 processado\n",
      "processando o arquivo: ./Dados/Microdados/MICRODADOS_ENEM_2023.csv\n",
      "Ano: 2023\n",
      "Arquivo de 2023 processado\n",
      "Compilando amostras\n",
      "Deu bom!\n"
     ]
    }
   ],
   "source": [
    "tipoDados = { ## definindo os tipos de dados\n",
    "    'NU_INSCRICAO': 'int64',\n",
    "    'NU_ANO': 'Int64',\n",
    "    'TP_ANO_CONCLUIU': 'Int64',\n",
    "    'TP_FAIXA_ETARIA': 'category',\n",
    "    'TP_SEXO': 'category',\n",
    "    'TP_COR_RACA': 'category',\n",
    "    'TP_ESCOLA': 'category',\n",
    "    'TP_ENSINO': 'category',\n",
    "    'IN_TREINEIRO': 'category',\n",
    "    'TP_PRESENCA_CN': 'category', \n",
    "    'TP_PRESENCA_CH': 'category', \n",
    "    'TP_PRESENCA_LC': 'category', \n",
    "    'TP_PRESENCA_MT': 'category', \n",
    "    'SG_UF_ESC': 'category',\n",
    "    'TP_DEPENDENCIA_ADM_ESC': 'category',\n",
    "    'TP_LOCALIZACAO_ESC': 'category',\n",
    "    'Q001': 'category', 'Q002': 'category', 'Q005': 'category', \n",
    "    'Q006': 'category', 'Q022': 'category', 'Q024': 'category', \n",
    "    'Q025': 'category',\n",
    "    'NU_NOTA_CN': 'float32',\n",
    "    'NU_NOTA_CH': 'float32',\n",
    "    'NU_NOTA_LC': 'float32',\n",
    "    'NU_NOTA_MT': 'float32',\n",
    "    'NU_NOTA_REDACAO': 'float32'\n",
    "}\n",
    "\n",
    "selecionarColunas = list(tipoDados.keys()) ##atalho para declarar as colunas apenas uma vez, função keys pega as chaves do dicionario.\n",
    "lista_de_amostras = []\n",
    "for caminho_arquivo in lista_arquivos:\n",
    "\n",
    "    print(f\"processando o arquivo: {caminho_arquivo}\")\n",
    "    nome_arquivo = os.path.basename(caminho_arquivo)\n",
    "    \n",
    "    try:\n",
    "        ano = nome_arquivo.split('_')[-1].split('.')[0] \n",
    "        print(f\"Ano: {ano}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Não foi possivel identificar o ano\")\n",
    "\n",
    "    try:    \n",
    "        df_temp = pd.read_csv(caminho_arquivo, sep=';', encoding='latin1')\n",
    "        amostra = df_temp.sample(frac=0.05, random_state=42)\n",
    "        amostra = amostra[selecionarColunas]\n",
    "\n",
    "        if int(ano) == 2018: ##trocando o valor 3 pelo 4 para corrigir a base de 2018\n",
    "            print(\"Correção TP_Escola para 2018\")\n",
    "\n",
    "            correcao_escola = {\n",
    "                1:1,\n",
    "                2:2,\n",
    "                3:4,\n",
    "                4:3 \n",
    "            }\n",
    "            if 'tp_escola' in amostra['tp_escola'].replace(correcao_escola)\n",
    "\n",
    "        amostra = amostra.astype(tipoDados) ## convertendo os tipos de dados   \n",
    "        lista_de_amostras.append(amostra)\n",
    "        del df_temp\n",
    "        del amostra\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Arquivo {ano} processado\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro {caminho_arquivo}: {e}\")\n",
    "\n",
    "if lista_de_amostras:\n",
    "\n",
    "    print(\"Compilando amostras\")\n",
    "    df_compilado = pd.concat(lista_de_amostras, ignore_index=True) ##isso aqui ignora o indice para reorganizar\n",
    "    local_saida = './Dados/Microdados/amostra_compilada.parquet'\n",
    "    df_compilado.to_parquet(local_saida, index=False)\n",
    "\n",
    "    print(\"Deu bom!\")\n",
    "else:\n",
    "    print(\"Deu ruim! :(\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
